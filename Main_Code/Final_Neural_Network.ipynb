{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "FINAL NEURAL NETWORK CODE\n",
    "Created by: Udacity (C)\n",
    "Modified by: Maryam Hanna\n",
    "Date: June 1, 2019\n",
    "Email: maryamhanna@hotmail.com\n",
    "MIT License, Permission is granted by Udacity(c) to obtain copy of this software. License could be found at LICENSE file. \n",
    "This algorithm trains a neural network to accurately detect license plates. This code requires 'data.csv' which should contain the file's location for training the neural network. The current setup algorithm trains 108 different neural networks. The user could modify the  differnt types of dropout levels, the number of dense layer, the number of convolution layer, and the size of the hidden layer. \n",
    "If for whatever reason, the neural network crashes, the user does not have to restart the whole training process, they could count the number the neural network is at and modify count at variable. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, MaxPooling2D, Dropout\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "import keras.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_neural_network function\n",
    "This function trains a neural network with the given data and conditions, and then saves the model and clears the computerâ€™s memory so it does not crash.  \n",
    "'''\n",
    "def train_neural_network(data_loc, \n",
    "                         dropout_precent, \n",
    "                         dense_,\n",
    "                         conv_,\n",
    "                         size_, \n",
    "                         batch__, \n",
    "                         learning_rate, \n",
    "                         learning_decay, \n",
    "                         epochs_, \n",
    "                         savemodel_loc): \n",
    "# reading in the labeled data from data.csv\n",
    "data = []\n",
    "with open(data_loc) as file:\n",
    "    reader = csv.reader(file)\n",
    "    for line in reader:\n",
    "        data.append(line)\n",
    "# splitting the read data into training, and validation sets\n",
    "train_data, valid_data = train_test_split(data, test_size=0.25)\n",
    "'''\n",
    "generator function\n",
    "When this function is called, it reads in the input lines of the data and its\n",
    "labels, along with the batch size. It returns an array of the images, and their measurements.\n",
    "Its a yield return type of function: meaning, it doesn't lose track of where it is in the input lines.\n",
    "'''\n",
    "def generator(input_lines, batch_size):\n",
    "    num_samples = len(input_lines)\n",
    "    while 1:\n",
    "        shuffle(input_lines)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_lines = input_lines[offset:offset+batch_size]\n",
    "            images = []\n",
    "            measurements = []\n",
    "            for each_batch_line in batch_lines:\n",
    "                current_path=each_batch_line[0]\n",
    "                image=cv2.imread(current_path)\n",
    "                # image resized and brought to binary neural network\n",
    "                image = cv2.resize(image, (140,70))\n",
    "                image = image/255.0\n",
    "                images.append(image)\n",
    "                measurement=each_batch_line[1]\n",
    "                measurements.append(measurement)\n",
    "            images = np.array(images).reshape(-1, 140, 70, 3)  \n",
    "            yield np.array(images), np.array(measurements)\n",
    "# compile and train the model using generator function, \n",
    "batch_size= batch__size\n",
    "train_gen = generator(train_data, batch_size)\n",
    "valid_gen = generator(valid_data, batch_size)\n",
    "# activating access to GPU -- comment out if using CPU only\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))\n",
    "# using GPU percentage 75%; modify as need be\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.75)\n",
    "sess=tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "# setting up the different types of neural networks to be constructed\n",
    "count = 0\n",
    "dropouts = dropout_precent\n",
    "dense_layers = dense_\n",
    "conv_layers = conv_\n",
    "layer_sizes = size_\n",
    "for dropout in dropouts:\n",
    "    for dense in dense_layers:\n",
    "        for conv in conv_layers:\n",
    "            for size in layer_sizes:\n",
    "                if count => 0:\n",
    "                    NAME = 'drop' + str(int(dropout*100)) + '_dense' + \n",
    "                            str(dense) + '_conv' + str(conv)+ '_size' \n",
    "                            +str(size)\n",
    "                    print(NAME)\n",
    "                    # start of neural network\n",
    "                    model = Sequential()\n",
    "                    # input layer\n",
    "                    model.add(Conv2D(size, (1,1), \n",
    "                                     input_shape=(140,70,3))) \n",
    "                    model.add(Activation('relu'))\n",
    "                    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                    model.add(Activation('relu'))\n",
    "                    model.add(Dropout(dropout))\n",
    "                    # convolution layers\n",
    "                    for l in range(conv-1):\n",
    "                        model.add(Conv2D(size, (1,1)))\n",
    "                        model.add(Activation('relu'))\n",
    "                        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                        model.add(Activation('relu'))\n",
    "                        model.add(Dropout(dropout))\n",
    "                    model.add(Flatten())\n",
    "                    # dense layers -- set to all have 128 size\n",
    "                    for _ in range(dense):\n",
    "                        model.add(Dense(128))                                               \n",
    "                        model.add(Activation('relu'))  \n",
    "                        model.add(Dropout(dropout))\n",
    "                    # sigmoid operation for binary output\n",
    "                    model.add(Dense(1))\n",
    "                    model.add(Activation('sigmoid'))\n",
    "                    # adam optimizer is decaying learning rate network\n",
    "                    adam = Adam(lr=learning_rate, decay=learning_decay)\n",
    "                    # binary-crossentropy is used validate each epoch\n",
    "                    model.compile(optimizer=adam,\n",
    "                                  loss='binary_crossentropy',\n",
    "                                  metrics=['accuracy'])\n",
    "                    steps_per_epoch_=len(train_data)\n",
    "                    checkpointer = ModelCheckpoint(filepath=\n",
    "                                                  \"{}.hdf5\".format(NAME), \n",
    "                                                   verbose=1, \n",
    "                                                   save_best_only=True)\n",
    "                    tensorboard = TensorBoard(log_dir=\n",
    "                                                  \"logs/{}\".format(NAME))\n",
    "                                  history=model.fit_generator(train_gen, \n",
    "                                  steps_per_epoch=steps_per_epoch_, \n",
    "                                  validation_data=valid_gen, \n",
    "                                  validation_steps=len(valid_data), \n",
    "                                  verbose=1, epochs=epochs_, \n",
    "                                  callbacks=[tensorboard])\n",
    "                    # save model then clear memory to training next model\n",
    "                    model.save(\"{}{}.model\".format(savemodel_loc,NAME))\n",
    "                    print(\"saved model\")\n",
    "                    del model\n",
    "                    del history\n",
    "                else:\n",
    "                    count += 1\n",
    "# END OF CODE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
